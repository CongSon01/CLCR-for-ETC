{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flow_id</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>235</td>\n",
              "      <td>175</td>\n",
              "      <td>86</td>\n",
              "      <td>243</td>\n",
              "      <td>39</td>\n",
              "      <td>68</td>\n",
              "      <td>13</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>12</td>\n",
              "      <td>250</td>\n",
              "      <td>139</td>\n",
              "      <td>16</td>\n",
              "      <td>32</td>\n",
              "      <td>196</td>\n",
              "      <td>213</td>\n",
              "      <td>83</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>235</td>\n",
              "      <td>175</td>\n",
              "      <td>186</td>\n",
              "      <td>42</td>\n",
              "      <td>73</td>\n",
              "      <td>232</td>\n",
              "      <td>76</td>\n",
              "      <td>81</td>\n",
              "      <td>...</td>\n",
              "      <td>143</td>\n",
              "      <td>168</td>\n",
              "      <td>113</td>\n",
              "      <td>80</td>\n",
              "      <td>33</td>\n",
              "      <td>221</td>\n",
              "      <td>3</td>\n",
              "      <td>251</td>\n",
              "      <td>234</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>235</td>\n",
              "      <td>175</td>\n",
              "      <td>197</td>\n",
              "      <td>6</td>\n",
              "      <td>200</td>\n",
              "      <td>121</td>\n",
              "      <td>4</td>\n",
              "      <td>220</td>\n",
              "      <td>...</td>\n",
              "      <td>162</td>\n",
              "      <td>209</td>\n",
              "      <td>217</td>\n",
              "      <td>131</td>\n",
              "      <td>208</td>\n",
              "      <td>68</td>\n",
              "      <td>82</td>\n",
              "      <td>83</td>\n",
              "      <td>69</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>235</td>\n",
              "      <td>175</td>\n",
              "      <td>68</td>\n",
              "      <td>129</td>\n",
              "      <td>53</td>\n",
              "      <td>250</td>\n",
              "      <td>187</td>\n",
              "      <td>126</td>\n",
              "      <td>...</td>\n",
              "      <td>36</td>\n",
              "      <td>143</td>\n",
              "      <td>177</td>\n",
              "      <td>91</td>\n",
              "      <td>247</td>\n",
              "      <td>226</td>\n",
              "      <td>67</td>\n",
              "      <td>221</td>\n",
              "      <td>72</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>235</td>\n",
              "      <td>175</td>\n",
              "      <td>119</td>\n",
              "      <td>124</td>\n",
              "      <td>211</td>\n",
              "      <td>111</td>\n",
              "      <td>238</td>\n",
              "      <td>94</td>\n",
              "      <td>...</td>\n",
              "      <td>108</td>\n",
              "      <td>46</td>\n",
              "      <td>185</td>\n",
              "      <td>117</td>\n",
              "      <td>93</td>\n",
              "      <td>124</td>\n",
              "      <td>215</td>\n",
              "      <td>137</td>\n",
              "      <td>149</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329655</th>\n",
              "      <td>74621</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>230</td>\n",
              "      <td>228</td>\n",
              "      <td>114</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329656</th>\n",
              "      <td>74621</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>149</td>\n",
              "      <td>142</td>\n",
              "      <td>46</td>\n",
              "      <td>117</td>\n",
              "      <td>220</td>\n",
              "      <td>...</td>\n",
              "      <td>158</td>\n",
              "      <td>57</td>\n",
              "      <td>205</td>\n",
              "      <td>202</td>\n",
              "      <td>253</td>\n",
              "      <td>84</td>\n",
              "      <td>33</td>\n",
              "      <td>86</td>\n",
              "      <td>210</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329657</th>\n",
              "      <td>74621</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>240</td>\n",
              "      <td>254</td>\n",
              "      <td>109</td>\n",
              "      <td>104</td>\n",
              "      <td>212</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>115</td>\n",
              "      <td>211</td>\n",
              "      <td>79</td>\n",
              "      <td>238</td>\n",
              "      <td>81</td>\n",
              "      <td>11</td>\n",
              "      <td>121</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329658</th>\n",
              "      <td>74621</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>115</td>\n",
              "      <td>199</td>\n",
              "      <td>170</td>\n",
              "      <td>142</td>\n",
              "      <td>121</td>\n",
              "      <td>...</td>\n",
              "      <td>104</td>\n",
              "      <td>204</td>\n",
              "      <td>153</td>\n",
              "      <td>222</td>\n",
              "      <td>234</td>\n",
              "      <td>38</td>\n",
              "      <td>133</td>\n",
              "      <td>158</td>\n",
              "      <td>97</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329659</th>\n",
              "      <td>74621</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>169</td>\n",
              "      <td>55</td>\n",
              "      <td>215</td>\n",
              "      <td>218</td>\n",
              "      <td>186</td>\n",
              "      <td>120</td>\n",
              "      <td>94</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>115</td>\n",
              "      <td>164</td>\n",
              "      <td>192</td>\n",
              "      <td>237</td>\n",
              "      <td>78</td>\n",
              "      <td>211</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>329660 rows Ã— 258 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        flow_id   0    1    2    3    4    5    6    7    8  ...  247  248  \\\n",
              "0             1   3  235  175   86  243   39   68   13   24  ...   12  250   \n",
              "1             1   3  235  175  186   42   73  232   76   81  ...  143  168   \n",
              "2             1   3  235  175  197    6  200  121    4  220  ...  162  209   \n",
              "3             1   3  235  175   68  129   53  250  187  126  ...   36  143   \n",
              "4             1   3  235  175  119  124  211  111  238   94  ...  108   46   \n",
              "...         ...  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "329655    74621  23    3    3    0   53  230  228  114  210  ...    0    0   \n",
              "329656    74621  23    3    3    1  149  142   46  117  220  ...  158   57   \n",
              "329657    74621  23    3    3    0  240  254  109  104  212  ...    3    5   \n",
              "329658    74621  23    3    3    5  115  199  170  142  121  ...  104  204   \n",
              "329659    74621  70   27  169   55  215  218  186  120   94  ...    3    5   \n",
              "\n",
              "        249  250  251  252  253  254  255  Label  \n",
              "0       139   16   32  196  213   83   16      3  \n",
              "1       113   80   33  221    3  251  234      3  \n",
              "2       217  131  208   68   82   83   69      3  \n",
              "3       177   91  247  226   67  221   72      3  \n",
              "4       185  117   93  124  215  137  149      3  \n",
              "...     ...  ...  ...  ...  ...  ...  ...    ...  \n",
              "329655    0    0    0    0    0    0    0      4  \n",
              "329656  205  202  253   84   33   86  210      4  \n",
              "329657  115  211   79  238   81   11  121      4  \n",
              "329658  153  222  234   38  133  158   97      4  \n",
              "329659  115  164  192  237   78  211  158      4  \n",
              "\n",
              "[329660 rows x 258 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Specify the path to your Feather file\n",
        "feather_file_path = '/home/bkcs/Desktop/Project-IL--master/CustomerData/Capture_train_256.feather'\n",
        "df = pd.read_feather(feather_file_path)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_filtered = df[df['Label'] != 12]\n",
        "df_sorted = df_filtered.sort_values(by='Label')\n",
        "\n",
        "NUM_FEATURE = 256\n",
        "\n",
        "def data_processing(df, NUM_FEATURES):\n",
        "   y_train = df['Label']\n",
        "   flow_id = df['flow_id']\n",
        "\n",
        "   df = df/255\n",
        "\n",
        "   X_train = df.drop(['Label', 'flow_id'], axis=1)\n",
        "   X_train = X_train.to_numpy() / 255\n",
        "#    NUM_FEATURES = X_train.shape[1]\n",
        "  \n",
        "   # nhom 20packet thanh 1 flow\n",
        "   X_train = X_train.reshape(-1,20, NUM_FEATURES)\n",
        "\n",
        "   y_train = y_train.to_numpy()\n",
        "\n",
        "   # lay nhan cuoi cung\n",
        "   y_train = y_train.reshape(-1,20)[:,-1] #em chao anhb\n",
        "   return X_train, y_train\n",
        "\n",
        "X, y = data_processing(df_sorted, NUM_FEATURE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11961, 20, 256)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}\n"
          ]
        }
      ],
      "source": [
        "unique_elements = set(y_train)\n",
        "\n",
        "print(unique_elements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mTYJwdP91lEU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.optim as optim \n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "DEVICE = torch.device('cuda:0')\n",
        "\n",
        "# if not os.path.isdir('./Project-dir'):\n",
        "#   !git clone https://github.com/armando-larocca/Project-IL-\n",
        "\n",
        "# if not os.path.isdir('content/cifar100.py'):\n",
        "#   !mv '/content/Project-IL-/cifar100.py' '/content'  \n",
        "#   !mv '/content/Project-IL-/utils.py' '/content'  \n",
        "\n",
        "# if not os.path.isdir('content/cifarResnet.py'):\n",
        "#   !mv '/content/Project-IL-/cifarResnet.py' '/content'\n",
        "\n",
        "from cifarResnet import resnet32\n",
        "from cifar100 import *\n",
        "from SimpleCNN import *\n",
        "#from resnet import resnet18\n",
        "\n",
        "# Example data (replace this with your actual data)\n",
        "train_data_list = {'x': X_train, 'y': y_train}\n",
        "test_data_list = {'x': X_test, 'y': y_test}\n",
        "\n",
        "# Instantiate the model, loss function, and optimizer\n",
        "input_size = len(y_train)\n",
        "hidden_size = 64\n",
        "output_size = len(set(y_train))  # Assuming labels are 0-indexed\n",
        "# Hyper Parameters\n",
        "num_epochs = 10\n",
        "batch_size = 10\n",
        "learning_rate = 3e-4\n",
        "total_classes = len(set(y_train))\n",
        "num_classes = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv1d(20, 32, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(32, 32, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(64 * (256 // 4), 256)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(256, n_classes, bias=True)\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.n_known = 0\n",
        "\n",
        "        self.p = self.parameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "    \n",
        "    def increment_classes(self, n):\n",
        "      in_features = self.fc.in_features\n",
        "      out_features = self.fc.out_features\n",
        "      weight = self.fc.weight.data\n",
        "      bias = self.fc.bias.data\n",
        "\n",
        "      self.fc = nn.Linear(in_features, out_features+n, bias=True)\n",
        "      self.fc.weight.data[:out_features] = weight\n",
        "      self.fc.bias.data[:out_features] = bias\n",
        "      self.n_classes += n    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "upVUMZySkObo"
      },
      "source": [
        "**LwF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "90whUB387UAf"
      },
      "outputs": [],
      "source": [
        "def one_hot(labels,n_cls):\n",
        "  hot = torch.zeros(len(labels), n_cls)\n",
        "  hot[range(hot.shape[0]), labels]=1\n",
        "  \n",
        "  return hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gzlq0yNqkTUR"
      },
      "source": [
        "**Dataset preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KNqI49pZ1uuR"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from CustomDataset import *\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408),std=(0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408),std=(0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "\n",
        "# shf = []\n",
        "# for x in range(0,6):\n",
        "#   shf.append(x)\n",
        "\n",
        "# random.shuffle(shf)\n",
        "train_dataset = CustomDataset(train_data_list)\n",
        "test_dataset = CustomDataset(test_data_list)\n",
        "\n",
        "# train_dataset._shuffle_(shf)\n",
        "# test_dataset._shuffle_(shf)\n",
        "\n",
        "incr_train = train_dataset.__incremental_train_indexes__(1)\n",
        "incr_val = test_dataset.__incremental_val_indexes__(0)\n",
        "\n",
        "\n",
        "# Get the list of unique labels\n",
        "all_labels = list(set(train_dataset.targets))\n",
        "\n",
        "# Shuffle the labels randomly (you may want to use a fixed seed for reproducibility)\n",
        "# random.shuffle(all_labels)\n",
        "\n",
        "# Split the labels into 4 subsets, each with 3 labels\n",
        "num_subsets = 4\n",
        "labels_per_subset = 3\n",
        "\n",
        "subset_indices = [all_labels[i:i+labels_per_subset] for i in range(0, len(all_labels), labels_per_subset)]\n",
        "\n",
        "# Create subsets using the indices of labels\n",
        "decine_train = [Subset(train_dataset, [i for i in range(len(train_dataset)) if train_dataset.targets[i] in subset]) for subset in subset_indices]\n",
        "decine_val = [Subset(test_dataset, [i for i in range(len(test_dataset)) if test_dataset.targets[i] in subset]) for subset in subset_indices]\n",
        "\n",
        "# decine_train = []\n",
        "# decine_val = []\n",
        "\n",
        "# for i in range(0,3):\n",
        "#   val_dataset = Subset(test_dataset, incr_val[i])\n",
        "#   training_dataset = Subset(train_dataset, incr_train[i])\n",
        "#   decine_train.append(training_dataset)\n",
        "#   decine_val.append(val_dataset) \n",
        "\n",
        "\n",
        "\n",
        "# train_dataset = Cifar100(\".\\Data\", train=\\True, transform=transform)\n",
        "# test_dataset = Cifar100(\".\\Data\", train=False, transform=transform_test)\n",
        "\n",
        "# train_dataset._shuffle_(shf)\n",
        "# test_dataset._shuffle_(shf)\n",
        "\n",
        "# incr_train = train_dataset.__incremental_train_indexes__(1)\n",
        "# incr_val = test_dataset.__incremental_val_indexes__(0)\n",
        "\n",
        "# decine_train = []\n",
        "# decine_val = []\n",
        "\n",
        "# for i in range(0,10):\n",
        "#   val_dataset = Subset(test_dataset, incr_val[i])\n",
        "#   training_dataset = Subset(train_dataset, incr_train[i])\n",
        "#   decine_train.append(training_dataset)\n",
        "#   decine_val.append(val_dataset) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_loader = torch.utils.data.DataLoader(decine_train[int(0)],batch_size=batch_size,shuffle=True)\n",
        "# net = ConvNet()\n",
        "# net.cuda()\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# # q = torch.zeros(50000, net.n_classes).cuda()\n",
        "# for  indices, images, labels in train_loader:\n",
        "#     images = Variable(images).cuda()\n",
        "\n",
        "#     indices = indices.cuda()\n",
        "#     old_out = net.forward(images.cuda())\n",
        "#     print(old_out.data)\n",
        "\n",
        "    # images = Variable(images).cuda()\n",
        "    # indices = indices.cuda()\n",
        "    # old_out = net.forward(images.cuda())\n",
        "    # # one_hot_batch = one_hot(labels,net.n_classes)\n",
        "    # # print(images.shape)\n",
        "    # print(old_out.cuda().shape)\n",
        "    # print(labels.cuda().shape)\n",
        "\n",
        "    # criterion(old_out.cuda(), labels.cuda())\n",
        "    # one_hot_batch = one_hot(labels,net.n_classes)\n",
        "    # print(one_hot_batch)\n",
        "    \n",
        "# q = Variable(q).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GLTsEtmpkZxG"
      },
      "source": [
        "**Main**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "248\n",
            "64\n",
            "Epoch [1/10], Loss: nan, Acc: 0.36\n",
            "Test Accuracy 0.3665086887835703\n",
            "222\n",
            "56\n",
            "New n_class: 6\n",
            "Epoch [1/10], Loss: nan, Acc: 0.00\n",
            "Test Accuracy 0.0\n",
            "575\n",
            "144\n",
            "New n_class: 9\n",
            "Epoch [1/10], Loss: nan, Acc: 0.00\n",
            "Test Accuracy 0.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "net = ConvNet(3)\n",
        "\n",
        "best_acc = []\n",
        "tot_matrix = []\n",
        "tot_labe = []\n",
        "\n",
        "for s in range(0,3):\n",
        "\n",
        "  net.cuda()\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(decine_train[int(s)], batch_size=batch_size,shuffle=True)\n",
        "  test_loader = torch.utils.data.DataLoader(decine_val[int(s)], batch_size=batch_size,shuffle=True)\n",
        "\n",
        "  print(len(train_loader))\n",
        "  print(len(test_loader))\n",
        "\n",
        "  #### OLD OUTPUT ### \n",
        "  q = torch.zeros(len(X_train), net.n_classes).cuda()\n",
        "  for  indices, images, labels in train_loader:\n",
        "    images = Variable(images).cuda()\n",
        "    indices = indices.cuda()\n",
        "    old_out = net.forward(images.cuda())\n",
        "    q[indices] = old_out.data\n",
        "    \n",
        "  q = Variable(q).cuda()\n",
        "  \n",
        "  if(s!=0):\n",
        "    net.increment_classes(3)\n",
        "    print(\"New n_class:\", net.n_classes)\n",
        "\n",
        "  net.cuda()\n",
        "  net.train(True)\n",
        "  p = net.parameters()\n",
        "  optimizer = optim.SGD(p, lr=2.0,weight_decay=0.00001,momentum=0.9) \n",
        "  scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [49,63], gamma=0.2)\n",
        "    \n",
        "  matrix = []\n",
        "  labe = []    \n",
        "  b_ac = 0\n",
        "\n",
        "  #### TRAIN ### \n",
        "  for epoch in range(0,1):\n",
        "\n",
        "    running_corrects = 0 \n",
        "    total = 0\n",
        "\n",
        "    for indices, images, labels in train_loader:\n",
        "      images = Variable(images).cuda()\n",
        "      labels = Variable(labels).cuda()\n",
        "      indices = indices.cuda()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      g = net.forward(images.cuda())\n",
        "\n",
        "      _, preds = torch.max(g, 1)\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "      total += labels.size(0)\n",
        "\n",
        "      ##### LOSS #######\n",
        "      q_i = q[indices]\n",
        "      one_hot_batch = one_hot(labels,net.n_classes)\n",
        "      sigmoid = nn.Sigmoid()\n",
        "      criterio=nn.BCEWithLogitsLoss() \n",
        "      criterio1= nn.CrossEntropyLoss()\n",
        "      criterio \n",
        "      q_i.cuda()\n",
        "      g.cuda()\n",
        "\n",
        "      if(net.n_classes==3):\n",
        "        loss = criterio(g, one_hot_batch.cuda())  \n",
        "      else: \n",
        "        x1 = q_i[:,:net.n_classes-3]\n",
        "        x2 = one_hot_batch[: ,net.n_classes-3 :net.n_classes]            \n",
        "        target = torch.cat( (sigmoid(x1), x2.cuda()) , 1)\n",
        "        loss = criterio(g, target)\n",
        "        \n",
        "      ####################\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    accuracy = running_corrects / float(total)       \n",
        "    scheduler.step()\n",
        "    print ('Epoch [%d/%d], Loss: %.4f, Acc: %.2f' %(epoch+1, num_epochs, loss.data, accuracy)) \n",
        "    \n",
        "    #### TEST ####\n",
        "    m=[]\n",
        "    l=[]\n",
        "    net.train(False)\n",
        "\n",
        "    total = 0.0\n",
        "    running_corrects = 0\n",
        "    for indices, images, labels in test_loader:\n",
        "        images = Variable(images).cuda()\n",
        "        out = net.forward(images)\n",
        "        _, preds = torch.max(out, 1)\n",
        "        running_corrects += torch.sum(preds.cpu() == labels.data).data.item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        m.extend(preds) \n",
        "        l.extend(labels)\n",
        "\n",
        "    matrix.append(m)\n",
        "    labe.append(l)     \n",
        "\n",
        "    accuracy = float(running_corrects / float(total))\n",
        "    print('Test Accuracy',accuracy)\n",
        "\n",
        "    if(b_ac < accuracy):\n",
        "      b_ac = accuracy \n",
        "\n",
        "  tot_matrix.append(matrix)\n",
        "  tot_labe.append(labe)\n",
        "  best_acc.append(b_ac)       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RPiYYD5Gkk4r"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "EAeO7Kb_W2Wj"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x1500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np \n",
        "import matplotlib \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tacche = [3,6,9,12]\n",
        "\n",
        "x =  tot_matrix[0][0]\n",
        "l = tot_labe[0][0]\n",
        "\n",
        "l =[int(i) for i in l]\n",
        "x =[int(i) for i in x]\n",
        "\n",
        "cf = confusion_matrix(list(l),list(x))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "im = ax.imshow(cf,cmap = 'plasma')\n",
        "\n",
        "ax.set_yticks(tacche)\n",
        "ax.set_xticks(tacche)\n",
        "\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
        "ax.set_title(\"image classification\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iCDG9HY_kna7"
      },
      "source": [
        "**Accuracy plot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XqNufSEAmLSC"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (4,) and (3,)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_491027/3512290434.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'k-o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Classes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \"\"\"\n\u001b[1;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (4,) and (3,)"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig,ax = plt.subplots(figsize=(15,10))\n",
        "ax.plot([3,6,9,12],best_acc,'k-o')\n",
        "plt.xlim(10,100)\n",
        "plt.ylim(0,1)\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "print(best_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "LwF_jpynb.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
